{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW4-Q2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQCZZepJ3DwF"
      },
      "source": [
        "import numpy as np\n",
        "import scipy.stats\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from sklearn.model_selection import cross_val_score\n",
        "np.set_printoptions(suppress=True)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqNpQEMx3I5f"
      },
      "source": [
        "### Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pt0cGvuh1Hu2"
      },
      "source": [
        "\n",
        "def gen_class_samples(num_samples, priors, label_ids):\n",
        "    num_labels = len(label_ids)\n",
        "    class_samples = np.array([0]*num_labels)\n",
        "    for num_sample in range(num_samples):\n",
        "        pr = random.uniform(0.0, 1.0)\n",
        "        if pr <= priors[0]:\n",
        "            class_samples[0] += 1\n",
        "        elif pr <= priors[0] + priors[1]:\n",
        "            class_samples[1] += 1\n",
        "        elif pr <= priors[0] + priors[1] + priors[2]:\n",
        "            class_samples[2] += 1\n",
        "        else:\n",
        "            class_samples[3] +=1\n",
        "    \n",
        "    return class_samples\n",
        "\n",
        "def generate_data_pxgl(priors, means, covs, num_samples, label_ids):\n",
        "    class_samples = gen_class_samples(num_samples, priors, label_ids)\n",
        "\n",
        "    #generate class data\n",
        "    pxgls = np.array([], dtype=float).reshape(2,0)\n",
        "    labels = []\n",
        "    for label_id in label_ids:\n",
        "        num_cls_samples = class_samples[label_id]\n",
        "        mean = means[label_id]\n",
        "        cov = covs[label_id]\n",
        "        pxgl = np.random.multivariate_normal(mean, cov, num_cls_samples).T\n",
        "        pxgls = np.concatenate((pxgls, pxgl), axis=1)\n",
        "        class_label = [label_id]*num_cls_samples\n",
        "        labels += class_label\n",
        "\n",
        "    labels = np.array(labels).reshape((1, -1))\n",
        "    data = np.concatenate((pxgls, labels), axis=0)\n",
        "\n",
        "    return data,class_samples\n",
        "\n",
        "def generate_data_pxgl_samples(samples_type, priors, means, covs, label_ids):\n",
        "    for i, key in enumerate(samples_type.keys()):\n",
        "        sample_type = samples_type[key]\n",
        "        num_samples = int(sample_type[0][0])\n",
        "        data_wt_labels, cls_samples = generate_data_pxgl(priors, means, covs, num_samples,label_ids)\n",
        "        sample_type[1] = cls_samples\n",
        "        sample_type[2] = data_wt_labels\n",
        "        label_names = [\"True label distribution of \" + str(num_samples) + \" samples using four components\", \"x\", \"y\"]\n",
        "        plot_dist(data_wt_labels, label_names, label_ids)  \n",
        "    \n",
        "    return samples_type\n",
        "\n",
        "def plot_dist(data, label_names, label_ids):\n",
        "    tname, xname, yname = label_names\n",
        "    print('***** plots *****')\n",
        "    samples = split_data(data, label_ids)\n",
        "    colors = ['red', 'blue', 'green', 'brown']\n",
        "    for label_id, sample in enumerate(samples):\n",
        "        plt.scatter(sample[0, :], sample[1, :], s=5, color = colors[label_id], label = 'class ' + str(label_id), marker='*')\n",
        "\n",
        "    plt.title(tname)\n",
        "    plt.xlabel(xname)\n",
        "    plt.ylabel(yname)\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "def split_data(data_wt_labels, label_ids):\n",
        "    samples = []\n",
        "    for label_id in label_ids:\n",
        "        class_ids = np.where(data_wt_labels[-1,:]==label_id)[0]\n",
        "        cls_samples = data_wt_labels[:,class_ids]\n",
        "        samples.append(cls_samples)\n",
        "    \n",
        "    return samples\n",
        "\n",
        "def plot_hist(num_gmm_freq, num_samples, num_time):\n",
        "    #print('num_gmm_freq: ',num_gmm_freq)\n",
        "    n_bins = len(num_gmm_lst)\n",
        "    fig, ax = plt.subplots(tight_layout=True)\n",
        "    ax.set_xlim([1, 6])\n",
        "    ax.hist(num_gmm_freq, bins=n_bins)\n",
        "    plt.title('Frequency of model order across 35 experiments for ' + str(num_samples) + 'samples')\n",
        "    plt.xlabel('GMM model orders')\n",
        "    plt.ylabel('Frequency of GMM model order')\n",
        "    plt.show()\n",
        "\n",
        "def MOS(sample_type, kfold, num_repeat):\n",
        "    num_samples = sample_type[0][0]\n",
        "    num_gmm_freq = np.zeros((num_repeat,), dtype=int)\n",
        "    for num_time in range(num_repeat):\n",
        "        data_wt_labels, cls_samples = generate_data_pxgl(priors, means, covs, num_samples,\n",
        "        label_ids)\n",
        "        data_wt_labels = data_wt_labels[:, np.random.permutation(data_wt_labels.shape[1])]\n",
        "\n",
        "        data = data_wt_labels[:2,:].T #(N, 2)\n",
        "        labels = data_wt_labels[2,:].T\n",
        "        gmm_mean = np.zeros((len(num_gmm_lst),), dtype=float)\n",
        "        gmm_std = np.zeros((len(num_gmm_lst),), dtype=float)\n",
        "        for num_gmm in num_gmm_lst:\n",
        "            GMM = GaussianMixture(num_gmm, covariance_type='full', random_state=0)\n",
        "            scores = cross_val_score(GMM, data, labels, cv=kfold)\n",
        "            mean_scores = np.mean(scores)\n",
        "            std_scores = np.std(scores)\n",
        "            gmm_mean[num_gmm-1] = mean_scores\n",
        "            gmm_std[num_gmm-1] = std_scores\n",
        "            #print('num_samples: ', num_samples, ' num_gmm: ', num_gmm,' mean_scores: ',np.round(mean_scores, 4), ' std_scores: ', np.round(std_scores, 4))\n",
        "        \n",
        "        desired_num_gmm = np.argmin(abs(gmm_mean)) + 1\n",
        "        #print('desired_num_gmm ',desired_num_gmm)\n",
        "        num_gmm_freq[num_time] = desired_num_gmm   \n",
        "\n",
        "    plot_hist(num_gmm_freq, num_samples, num_time+1)\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RxVob6vI3WVN"
      },
      "source": [
        "A 2-dimensional real-valued random vector was generated using a Gaussian\n",
        "Mixture Model (GMM) with 4 components. Each of these components have different mean vectors, different covariance matrices and different prior.\n",
        "\n",
        "$m_1 = \\begin{bmatrix}35 \\\\ 0\\end{bmatrix}$\n",
        "$m_2 = \\begin{bmatrix}35 \\\\ 52.5\\end{bmatrix}$\n",
        "$m_3 = \\begin{bmatrix}0 \\\\ 0\\end{bmatrix}$\n",
        "$m_4 = \\begin{bmatrix}0 \\\\ 52.5\\end{bmatrix}$\n",
        "\n",
        "\n",
        "$C_1 = \\begin{bmatrix}10 & 20 \\\\ 0 & 40\\end{bmatrix}$\n",
        "$C_2 = \\begin{bmatrix}20 & 0 \\\\ 40 & 5\\end{bmatrix}$\n",
        "$C_3 = \\begin{bmatrix}20 & 30 \\\\ 0 & 10\\end{bmatrix}$\n",
        "$C_4 = \\begin{bmatrix}5 & 0 \\\\ 10 & 20\\end{bmatrix}$\n",
        "\n",
        "$P(L=0) = 0.1$\n",
        "$P(L=1) = 0.2$\n",
        "$P(L=2) = 0.3$\n",
        "$P(L=3) = 0.4$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NptdzZ0l1pt5"
      },
      "source": [
        "\n",
        "if __name__ == \"__main__\":\n",
        "    dim = 2\n",
        "    label_ids = [0, 1, 2, 3]\n",
        "    num_labels = len(label_ids)\n",
        "    priors = [0.1, 0.2, 0.3, 0.4]\n",
        "    kfold = 10\n",
        "    num_repeat = 35\n",
        "    num_gmm_lst = [1, 2, 3, 4, 5, 6]\n",
        "\n",
        "    samples_type = {\n",
        "                    'D10': [[10], [], []],\\\n",
        "                    'D100': [[100], [], []],\\\n",
        "                    'D1k': [[1000], [], []],\\\n",
        "                    'D10k': [[10000], [], []],\n",
        "                }\n",
        "\n",
        "    m0 = np.array([35, 0])\n",
        "    m1 = np.array([35, 52.5])\n",
        "    m2 = np.array([0, 0])\n",
        "    m3 = np.array([0, 52.5])\n",
        "    C0 = np.array([[10, 20], [0, 40]])\n",
        "    C1 = np.array([[20, 0], [40, 5]])\n",
        "    C2 = np.array([[20, 30], [0, 10]])\n",
        "    C3 = np.array([[5, 0], [10, 20]])\n",
        "    means = [m0, m1, m2, m3]\n",
        "    covs = [C0, C1, C2, C3]\n",
        "    \n",
        "\n",
        "    #Model Order Selection\n",
        "    for i, key in enumerate(list(samples_type.keys())):\n",
        "        MOS(samples_type[key], kfold, num_repeat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clEqoLLw50SG"
      },
      "source": [
        "10-fold cross-validation to find the best number of GMM components for each of the above-mentioned datasets. The number of GMM components used for model selection were 1, 2, 3, 4, 5, and 6.\n",
        "\n",
        "The iterative numerical optimization method used here is Expectation-Maximization(EM) algorithm. This algorithm maximizes the expected value of the log likelihood function of Î¸ as shown below.\n",
        "\n",
        "| Dataset | 1    | 2   | 3 | 4    | 5    | 6    |\n",
        "|---------|------|-----|---|------|------|------|\n",
        "| T10     | 0.91 | 0.9 | 0 | 0    | 0    | 0.0  |\n",
        "| T100    | 0    | 0   | 0 | 0.94 | 0.06 | 0.0  |\n",
        "| T1K     | 0    | 0   | 0 | 0.54 | 0.34 | 0.11 |\n",
        "| T10K    | 0    | 0   | 0 | 0.85 | 0.15 | 0.0  |\n",
        "\n",
        "A very general trend that was found that higher number of gaussian component model was selected when more data was available\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHpYWr3y8M6C"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}